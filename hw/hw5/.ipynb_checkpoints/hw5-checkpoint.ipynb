{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 5: Evaluation metrics\n",
    "### Associated lectures: [Lectures 9, 10](https://ubc-cs.github.io/cpsc330/README.html) \n",
    "\n",
    "**Due date: Monday, Feb 28, 2022 at 11:59pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tests_hw5\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:3}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330/blob/master/docs/homework_instructions.md). \n",
    "\n",
    "**You may work with a partner on this homework and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 2. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Precision, recall, and f1 score by hand <a name=\"1\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem of predicting whether a patient has a disease or not. Below are confusion matrices of two machine learning models: Model A and Model B. \n",
    "\n",
    "- Model A\n",
    "\n",
    "|    Actual/Predicted      | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 18 | 22 |\n",
    "| **Actual no disease**       | 10 | 100 |\n",
    "\n",
    "\n",
    "- Model B\n",
    "\n",
    "|    Actual/Predicted      | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 23 | 17 |\n",
    "| **Actual no disease**       | 20 | 90 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Positive vs. negative class \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Precision, recall, and f1 score depend upon which class is considered \"positive\", that is the thing you wish to find. In the example above, which class is likely to be the \"positive\" class? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution : The class we consider positive is patients that have the disease. We can see that there is a large class imbalance due to the number of no disease being higher by several magnitudes. Because of the imbalance we can assume that the disease we are looking for is rare and we eventually would like to tune the ML model to ensure that we capture the diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Accuracy\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Calculate accuracies for Model A and Model B. \n",
    "\n",
    "We'll store all metrics associated with Model A and Model B in the `results_dict` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\"A\": {}, \"B\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"accuracy\"] = (118)/(150)\n",
    "results_dict[\"B\"][\"accuracy\"] = 113/150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_2_1(\n",
    "    results_dict[\"A\"][\"accuracy\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_2_2(\n",
    "    results_dict[\"B\"][\"accuracy\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.753333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A         B\n",
       "accuracy  0.786667  0.753333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Which model would you pick? \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Which model would you pick simply based on the accuracy metric? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution: Based on just above we would pick model A as it has the higher accuracy metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Precision, recall, f1-score\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Calculate precision, recall, f1-score for Model A and Model B manually, without using `scikit-learn` tools. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"precision\"] = 18/28\n",
    "results_dict[\"B\"][\"precision\"] = 23/43\n",
    "results_dict[\"A\"][\"recall\"] = 18/40\n",
    "results_dict[\"B\"][\"recall\"] = 23/40\n",
    "results_dict[\"A\"][\"f1\"] = (2*(18/28)*(18/40)/((18/28)+(18/40)))\n",
    "results_dict[\"B\"][\"f1\"] = (2*(23/43)*(23/40)/((23/43)+(23/40)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_1(\n",
    "    results_dict[\"A\"][\"precision\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_2(\n",
    "    results_dict[\"B\"][\"precision\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_3(\n",
    "    results_dict[\"A\"][\"recall\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_4(\n",
    "    results_dict[\"B\"][\"recall\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_5(\n",
    "    results_dict[\"A\"][\"f1\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_6(\n",
    "    results_dict[\"B\"][\"f1\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the dataframe with all results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.753333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.534884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.554217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A         B\n",
       "accuracy   0.786667  0.753333\n",
       "precision  0.642857  0.534884\n",
       "recall     0.450000  0.575000\n",
       "f1         0.529412  0.554217"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Discussion\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Which metric is more informative in this problem? Why? \n",
    "2. Which model would you pick based on this information? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 1\n",
    "The Metric Recall would be more informative for this problem. We are interested in a high positive capture rate, even at the expense of increasing the rate of false positive. This is because detecting a rare disease would be more important than leaving a disease undetected. \n",
    "\n",
    "# Solution 2 \n",
    "Based on this information we would pick Model 2 as it would have a higher recall score. We do see a drop in precision but that is something that we would give up to obtain a higher recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 1.6 \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Provide 2 to 3 example classification datasets (with links) where accuracy metric would be misleading. Discuss which evaluation metric would be more appropriate for each dataset. You may consider datasets we have used in this course so far. You could also look up datasets on Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Classification evaluation metrics using `sklearn` <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "In general, when a dataset is imbalanced, accuracy does not provide the whole story. In class, we looked at credit card fraud dataset which is a classic example of an imbalanced dataset. \n",
    "\n",
    "Another example is customer churn datasets. [Customer churn](https://en.wikipedia.org/wiki/Customer_attrition) refers to the notion of customers leaving a subscription service like Netflix. In this exercise, we will try to predict customer churn in a dataset where most of the customers stay with the service and a small minority cancel their subscription. To start, please download the [Kaggle telecom customer churn dataset](https://www.kaggle.com/becksddf/churn-in-telecoms-dataset). Once you have the data, you should be able to run the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starter code below reads the data CSV as a pandas dataframe and splits it into 70% train and 30% test. \n",
    "\n",
    "Note that `churn` column in the dataset is the target. \"True\" means the customer left the subscription (churned) and \"False\" means they stayed.\n",
    "\n",
    "> Note that for this kind of problem a more appropriate technique is something called survival analysis and we'll be talking about it later in the course. For now, we'll just treat it as a binary classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>NE</td>\n",
       "      <td>70</td>\n",
       "      <td>415</td>\n",
       "      <td>421-8535</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>213.4</td>\n",
       "      <td>86</td>\n",
       "      <td>36.28</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>17.40</td>\n",
       "      <td>256.6</td>\n",
       "      <td>101</td>\n",
       "      <td>11.55</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>WI</td>\n",
       "      <td>67</td>\n",
       "      <td>510</td>\n",
       "      <td>417-2265</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>134</td>\n",
       "      <td>18.55</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>12.10</td>\n",
       "      <td>91.2</td>\n",
       "      <td>86</td>\n",
       "      <td>4.10</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>NJ</td>\n",
       "      <td>122</td>\n",
       "      <td>415</td>\n",
       "      <td>327-9341</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>34</td>\n",
       "      <td>146.4</td>\n",
       "      <td>104</td>\n",
       "      <td>24.89</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>7.62</td>\n",
       "      <td>220.0</td>\n",
       "      <td>91</td>\n",
       "      <td>9.90</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4</td>\n",
       "      <td>4.21</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>NV</td>\n",
       "      <td>107</td>\n",
       "      <td>510</td>\n",
       "      <td>419-9688</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>234.1</td>\n",
       "      <td>91</td>\n",
       "      <td>39.80</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>13.86</td>\n",
       "      <td>282.5</td>\n",
       "      <td>100</td>\n",
       "      <td>12.71</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>HI</td>\n",
       "      <td>105</td>\n",
       "      <td>510</td>\n",
       "      <td>364-8128</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>125.4</td>\n",
       "      <td>116</td>\n",
       "      <td>21.32</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>22.23</td>\n",
       "      <td>241.6</td>\n",
       "      <td>104</td>\n",
       "      <td>10.87</td>\n",
       "      <td>11.4</td>\n",
       "      <td>9</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>WY</td>\n",
       "      <td>126</td>\n",
       "      <td>408</td>\n",
       "      <td>339-9798</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>197.6</td>\n",
       "      <td>126</td>\n",
       "      <td>33.59</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>20.95</td>\n",
       "      <td>285.3</td>\n",
       "      <td>104</td>\n",
       "      <td>12.84</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>WV</td>\n",
       "      <td>70</td>\n",
       "      <td>510</td>\n",
       "      <td>348-3777</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>143.4</td>\n",
       "      <td>72</td>\n",
       "      <td>24.38</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>14.45</td>\n",
       "      <td>127.9</td>\n",
       "      <td>68</td>\n",
       "      <td>5.76</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>NJ</td>\n",
       "      <td>125</td>\n",
       "      <td>415</td>\n",
       "      <td>406-6400</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>182.3</td>\n",
       "      <td>64</td>\n",
       "      <td>30.99</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>11.88</td>\n",
       "      <td>171.6</td>\n",
       "      <td>96</td>\n",
       "      <td>7.72</td>\n",
       "      <td>11.6</td>\n",
       "      <td>7</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>NE</td>\n",
       "      <td>159</td>\n",
       "      <td>415</td>\n",
       "      <td>362-5111</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>189.1</td>\n",
       "      <td>105</td>\n",
       "      <td>32.15</td>\n",
       "      <td>...</td>\n",
       "      <td>147</td>\n",
       "      <td>20.92</td>\n",
       "      <td>242.0</td>\n",
       "      <td>106</td>\n",
       "      <td>10.89</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>PA</td>\n",
       "      <td>106</td>\n",
       "      <td>408</td>\n",
       "      <td>403-9167</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>133.7</td>\n",
       "      <td>45</td>\n",
       "      <td>22.73</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>15.96</td>\n",
       "      <td>181.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.19</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2333 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  account length  area code phone number international plan  \\\n",
       "1402    NE              70        415     421-8535                 no   \n",
       "1855    WI              67        510     417-2265                 no   \n",
       "633     NJ             122        415     327-9341                 no   \n",
       "1483    NV             107        510     419-9688                yes   \n",
       "2638    HI             105        510     364-8128                 no   \n",
       "...    ...             ...        ...          ...                ...   \n",
       "2154    WY             126        408     339-9798                yes   \n",
       "3089    WV              70        510     348-3777                 no   \n",
       "1766    NJ             125        415     406-6400                 no   \n",
       "1122    NE             159        415     362-5111                 no   \n",
       "1346    PA             106        408     403-9167                yes   \n",
       "\n",
       "     voice mail plan  number vmail messages  total day minutes  \\\n",
       "1402              no                      0              213.4   \n",
       "1855              no                      0              109.1   \n",
       "633              yes                     34              146.4   \n",
       "1483              no                      0              234.1   \n",
       "2638              no                      0              125.4   \n",
       "...              ...                    ...                ...   \n",
       "2154              no                      0              197.6   \n",
       "3089             yes                     30              143.4   \n",
       "1766              no                      0              182.3   \n",
       "1122              no                      0              189.1   \n",
       "1346              no                      0              133.7   \n",
       "\n",
       "      total day calls  total day charge  ...  total eve calls  \\\n",
       "1402               86             36.28  ...               77   \n",
       "1855              134             18.55  ...               76   \n",
       "633               104             24.89  ...              103   \n",
       "1483               91             39.80  ...              105   \n",
       "2638              116             21.32  ...               95   \n",
       "...               ...               ...  ...              ...   \n",
       "2154              126             33.59  ...              112   \n",
       "3089               72             24.38  ...               92   \n",
       "1766               64             30.99  ...              121   \n",
       "1122              105             32.15  ...              147   \n",
       "1346               45             22.73  ...              107   \n",
       "\n",
       "      total eve charge  total night minutes  total night calls  \\\n",
       "1402             17.40                256.6                101   \n",
       "1855             12.10                 91.2                 86   \n",
       "633               7.62                220.0                 91   \n",
       "1483             13.86                282.5                100   \n",
       "2638             22.23                241.6                104   \n",
       "...                ...                  ...                ...   \n",
       "2154             20.95                285.3                104   \n",
       "3089             14.45                127.9                 68   \n",
       "1766             11.88                171.6                 96   \n",
       "1122             20.92                242.0                106   \n",
       "1346             15.96                181.9                 89   \n",
       "\n",
       "      total night charge  total intl minutes  total intl calls  \\\n",
       "1402               11.55                 5.7                 4   \n",
       "1855                4.10                10.9                 5   \n",
       "633                 9.90                15.6                 4   \n",
       "1483               12.71                10.0                 3   \n",
       "2638               10.87                11.4                 9   \n",
       "...                  ...                 ...               ...   \n",
       "2154               12.84                12.5                 8   \n",
       "3089                5.76                 9.4                 4   \n",
       "1766                7.72                11.6                 7   \n",
       "1122               10.89                10.4                 5   \n",
       "1346                8.19                10.7                 2   \n",
       "\n",
       "      total intl charge  customer service calls  churn  \n",
       "1402               1.54                       1  False  \n",
       "1855               2.94                       2  False  \n",
       "633                4.21                       2  False  \n",
       "1483               2.70                       1  False  \n",
       "2638               3.08                       2  False  \n",
       "...                 ...                     ...    ...  \n",
       "2154               3.38                       2  False  \n",
       "3089               2.54                       3  False  \n",
       "1766               3.13                       2  False  \n",
       "1122               2.81                       1   True  \n",
       "1346               2.89                       1   True  \n",
       "\n",
       "[2333 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bigml_59c28831336c6604c800002a.csv\", encoding=\"utf-8\")\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.850407\n",
       "True     0.149593\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"churn\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Distribution of target values\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Examine the distribution of target values in the train split. Do you see class imbalance? If yes, do we need to deal with it? Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution: Yes we see a class imbalance with 14.95% of values classified as True, and 85.05% of the remaining examples as False. We have many more False examples which is not ideal as True is the important class that we want to spot. In this case because there is a class imbalance as long as we are sure that our data collection method is not the reason for the imbalance we can begin to ask which type of error is more important and adjust our parameters to optimize one error over the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 2.2 EDA \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Come up with **two** exploratory questions you would like to answer and explore those. Briefly discuss your results in 1-3 sentences.\n",
    "\n",
    "You are welcome to use `pandas_profiling` (see Lecture 10) but you don't have to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Column transformer \n",
    "rubric={points:10}\n",
    "\n",
    "The code below creates `X_train`, `y_train`, `X_test`, `y_test` for you. \n",
    "In preparation for building a classifier, set up a `ColumnTransformer` that performs whatever feature transformations you deem sensible. This can include dropping features if you think they are not helpful. Remember that by default `ColumnTransformer` will drop any columns that aren't accounted for when it's created.\n",
    "\n",
    "In each case, briefly explain your rationale with 1-2 sentences. You do not need an explanation for every feature, but for every group of features that are being transformed the same way. For example, \"I am doing transformation X to the following categorical features: `a`, `b`, `c` because of reason Y,\" etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   3333 non-null   object \n",
      " 1   account length          3333 non-null   int64  \n",
      " 2   area code               3333 non-null   int64  \n",
      " 3   phone number            3333 non-null   object \n",
      " 4   international plan      3333 non-null   object \n",
      " 5   voice mail plan         3333 non-null   object \n",
      " 6   number vmail messages   3333 non-null   int64  \n",
      " 7   total day minutes       3333 non-null   float64\n",
      " 8   total day calls         3333 non-null   int64  \n",
      " 9   total day charge        3333 non-null   float64\n",
      " 10  total eve minutes       3333 non-null   float64\n",
      " 11  total eve calls         3333 non-null   int64  \n",
      " 12  total eve charge        3333 non-null   float64\n",
      " 13  total night minutes     3333 non-null   float64\n",
      " 14  total night calls       3333 non-null   int64  \n",
      " 15  total night charge      3333 non-null   float64\n",
      " 16  total intl minutes      3333 non-null   float64\n",
      " 17  total intl calls        3333 non-null   int64  \n",
      " 18  total intl charge       3333 non-null   float64\n",
      " 19  customer service calls  3333 non-null   int64  \n",
      " 20  churn                   3333 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(4)\n",
      "memory usage: 524.2+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.drop(columns=[\"churn\"])\n",
    "X_test = test_df.drop(columns=[\"churn\"])\n",
    "\n",
    "y_train = train_df[\"churn\"]\n",
    "y_test = test_df[\"churn\"]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "numeric_feats = [\"account length\",\n",
    "                 \"number vmail messages\",\n",
    "                 \"total day minutes\",\n",
    "                 \"total day calls\",\n",
    "                \"total day charge\",\n",
    "                \"total eve minutes\",\n",
    "                \"total eve calls\",\n",
    "                \"total eve charge\",\n",
    "                \"total night minutes\",\n",
    "                \"total night calls\",\n",
    "                \"total night charge\",\n",
    "                \"total intl minutes\",\n",
    "                \"total intl calls\",\n",
    "                \"total intl charge\",\n",
    "                \"customer service calls\"] # All numerical feats should be scaled to standardscaler\n",
    "categorical_feats = [\"state\"] # categorical feat with individual states\n",
    "binary_feats = [\"international plan\",\"voice mail plan\"] # Binary Feats with just yes or no\n",
    "drop_feats = [\"phone number\", \"area code\"] # dropping phone number as it is randomly assigned and should not have an affect on prediction. For area code we decide to drop this as we would determine drop rate with state instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('pipeline',\n",
       "                                 Pipeline(steps=[('standardscaler',\n",
       "                                                  StandardScaler())]),\n",
       "                                 ['account length', 'number vmail messages',\n",
       "                                  'total day minutes', 'total day calls',\n",
       "                                  'total day charge', 'total eve minutes',\n",
       "                                  'total eve calls', 'total eve charge',\n",
       "                                  'total night minutes', 'total night calls',\n",
       "                                  'total night charge', 'total intl minutes',\n",
       "                                  'total intl calls', 'total intl charge',\n",
       "                                  'customer service calls']),\n",
       "                                ('onehotencoder-1',\n",
       "                                 OneHotEncoder(handle_unknown='ignore',\n",
       "                                               sparse=False),\n",
       "                                 ['state']),\n",
       "                                ('onehotencoder-2',\n",
       "                                 OneHotEncoder(drop='if_binary',\n",
       "                                               dtype=<class 'int'>),\n",
       "                                 ['international plan', 'voice mail plan']),\n",
       "                                ('drop', 'drop',\n",
       "                                 ['phone number', 'area code'])])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = make_column_transformer(\n",
    "    (\n",
    "        make_pipeline(StandardScaler()),\n",
    "        numeric_feats,\n",
    "    ), # scaling on numeric features\n",
    "    (\n",
    "        OneHotEncoder(handle_unknown=\"ignore\",sparse=False), categorical_feats,\n",
    "    ),\n",
    "    (\n",
    "        OneHotEncoder(drop=\"if_binary\", dtype=int),binary_feats,\n",
    "    ),\n",
    "    (\n",
    "        \"drop\", drop_feats,\n",
    "    ),\n",
    ")\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualizing the transformed data \n",
    "rubric={points:4}\n",
    "\n",
    "Fit and transform your `ColumnTransformer` on your training set. Print the first 5 rows of the transformed data as a dataframe (not numpy array). See lecture 10 for code that can get you the new column names after transforming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed = ct.fit_transform(X_train)\n",
    "X_train_transformed\n",
    "type(X_train_transformed[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['account length',\n",
       " 'number vmail messages',\n",
       " 'total day minutes',\n",
       " 'total day calls',\n",
       " 'total day charge',\n",
       " 'total eve minutes',\n",
       " 'total eve calls',\n",
       " 'total eve charge',\n",
       " 'total night minutes',\n",
       " 'total night calls',\n",
       " 'total night charge',\n",
       " 'total intl minutes',\n",
       " 'total intl calls',\n",
       " 'total intl charge',\n",
       " 'customer service calls',\n",
       " 'state_AK',\n",
       " 'state_AL',\n",
       " 'state_AR',\n",
       " 'state_AZ',\n",
       " 'state_CA',\n",
       " 'state_CO',\n",
       " 'state_CT',\n",
       " 'state_DC',\n",
       " 'state_DE',\n",
       " 'state_FL',\n",
       " 'state_GA',\n",
       " 'state_HI',\n",
       " 'state_IA',\n",
       " 'state_ID',\n",
       " 'state_IL',\n",
       " 'state_IN',\n",
       " 'state_KS',\n",
       " 'state_KY',\n",
       " 'state_LA',\n",
       " 'state_MA',\n",
       " 'state_MD',\n",
       " 'state_ME',\n",
       " 'state_MI',\n",
       " 'state_MN',\n",
       " 'state_MO',\n",
       " 'state_MS',\n",
       " 'state_MT',\n",
       " 'state_NC',\n",
       " 'state_ND',\n",
       " 'state_NE',\n",
       " 'state_NH',\n",
       " 'state_NJ',\n",
       " 'state_NM',\n",
       " 'state_NV',\n",
       " 'state_NY',\n",
       " 'state_OH',\n",
       " 'state_OK',\n",
       " 'state_OR',\n",
       " 'state_PA',\n",
       " 'state_RI',\n",
       " 'state_SC',\n",
       " 'state_SD',\n",
       " 'state_TN',\n",
       " 'state_TX',\n",
       " 'state_UT',\n",
       " 'state_VA',\n",
       " 'state_VT',\n",
       " 'state_WA',\n",
       " 'state_WI',\n",
       " 'state_WV',\n",
       " 'state_WY',\n",
       " 'international plan',\n",
       " 'voice mail plan']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = (\n",
    "    numeric_feats\n",
    "    + ct.named_transformers_[\"onehotencoder-1\"].get_feature_names_out().tolist()\n",
    "    + binary_feats\n",
    ")\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account length</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>...</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.767893</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>0.618769</td>\n",
       "      <td>-0.721211</td>\n",
       "      <td>0.618927</td>\n",
       "      <td>0.069871</td>\n",
       "      <td>-1.156734</td>\n",
       "      <td>0.069926</td>\n",
       "      <td>1.088667</td>\n",
       "      <td>0.052115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.843585</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>-1.293778</td>\n",
       "      <td>1.655252</td>\n",
       "      <td>-1.293517</td>\n",
       "      <td>-1.167277</td>\n",
       "      <td>-1.207278</td>\n",
       "      <td>-1.166291</td>\n",
       "      <td>-2.162302</td>\n",
       "      <td>-0.720990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.544113</td>\n",
       "      <td>1.900976</td>\n",
       "      <td>-0.609809</td>\n",
       "      <td>0.169963</td>\n",
       "      <td>-0.609654</td>\n",
       "      <td>-2.210130</td>\n",
       "      <td>0.157417</td>\n",
       "      <td>-2.211244</td>\n",
       "      <td>0.369287</td>\n",
       "      <td>-0.463288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.165650</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>0.998345</td>\n",
       "      <td>-0.473663</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>-0.754894</td>\n",
       "      <td>0.258506</td>\n",
       "      <td>-0.755774</td>\n",
       "      <td>1.597736</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.115188</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>-0.994886</td>\n",
       "      <td>0.764078</td>\n",
       "      <td>-0.994731</td>\n",
       "      <td>1.195994</td>\n",
       "      <td>-0.246937</td>\n",
       "      <td>1.196515</td>\n",
       "      <td>0.793839</td>\n",
       "      <td>0.206736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>0.645037</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>0.329045</td>\n",
       "      <td>1.259175</td>\n",
       "      <td>0.328771</td>\n",
       "      <td>0.898602</td>\n",
       "      <td>0.612316</td>\n",
       "      <td>0.897957</td>\n",
       "      <td>1.652771</td>\n",
       "      <td>0.206736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>-0.767893</td>\n",
       "      <td>1.608200</td>\n",
       "      <td>-0.664820</td>\n",
       "      <td>-1.414346</td>\n",
       "      <td>-0.664665</td>\n",
       "      <td>-0.618094</td>\n",
       "      <td>-0.398570</td>\n",
       "      <td>-0.618157</td>\n",
       "      <td>-1.440956</td>\n",
       "      <td>-1.648715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>0.619806</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>0.048489</td>\n",
       "      <td>-1.810423</td>\n",
       "      <td>0.048322</td>\n",
       "      <td>-1.216842</td>\n",
       "      <td>1.067214</td>\n",
       "      <td>-1.217606</td>\n",
       "      <td>-0.582024</td>\n",
       "      <td>-0.205587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>1.477656</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>0.173180</td>\n",
       "      <td>0.219472</td>\n",
       "      <td>0.173445</td>\n",
       "      <td>0.890672</td>\n",
       "      <td>2.381365</td>\n",
       "      <td>0.890960</td>\n",
       "      <td>0.801701</td>\n",
       "      <td>0.309816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>0.140419</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>-0.842689</td>\n",
       "      <td>-2.751107</td>\n",
       "      <td>-0.842642</td>\n",
       "      <td>-0.265190</td>\n",
       "      <td>0.359594</td>\n",
       "      <td>-0.265952</td>\n",
       "      <td>-0.379576</td>\n",
       "      <td>-0.566369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2333 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      account length  number vmail messages  total day minutes  \\\n",
       "0          -0.767893              -0.587624           0.618769   \n",
       "1          -0.843585              -0.587624          -1.293778   \n",
       "2           0.544113               1.900976          -0.609809   \n",
       "3           0.165650              -0.587624           0.998345   \n",
       "4           0.115188              -0.587624          -0.994886   \n",
       "...              ...                    ...                ...   \n",
       "2328        0.645037              -0.587624           0.329045   \n",
       "2329       -0.767893               1.608200          -0.664820   \n",
       "2330        0.619806              -0.587624           0.048489   \n",
       "2331        1.477656              -0.587624           0.173180   \n",
       "2332        0.140419              -0.587624          -0.842689   \n",
       "\n",
       "      total day calls  total day charge  total eve minutes  total eve calls  \\\n",
       "0           -0.721211          0.618927           0.069871        -1.156734   \n",
       "1            1.655252         -1.293517          -1.167277        -1.207278   \n",
       "2            0.169963         -0.609654          -2.210130         0.157417   \n",
       "3           -0.473663          0.998611          -0.754894         0.258506   \n",
       "4            0.764078         -0.994731           1.195994        -0.246937   \n",
       "...               ...               ...                ...              ...   \n",
       "2328         1.259175          0.328771           0.898602         0.612316   \n",
       "2329        -1.414346         -0.664665          -0.618094        -0.398570   \n",
       "2330        -1.810423          0.048322          -1.216842         1.067214   \n",
       "2331         0.219472          0.173445           0.890672         2.381365   \n",
       "2332        -2.751107         -0.842642          -0.265190         0.359594   \n",
       "\n",
       "      total eve charge  total night minutes  total night calls  ...  state_TX  \\\n",
       "0             0.069926             1.088667           0.052115  ...       0.0   \n",
       "1            -1.166291            -2.162302          -0.720990  ...       0.0   \n",
       "2            -2.211244             0.369287          -0.463288  ...       0.0   \n",
       "3            -0.755774             1.597736           0.000574  ...       0.0   \n",
       "4             1.196515             0.793839           0.206736  ...       0.0   \n",
       "...                ...                  ...                ...  ...       ...   \n",
       "2328          0.897957             1.652771           0.206736  ...       0.0   \n",
       "2329         -0.618157            -1.440956          -1.648715  ...       0.0   \n",
       "2330         -1.217606            -0.582024          -0.205587  ...       0.0   \n",
       "2331          0.890960             0.801701           0.309816  ...       0.0   \n",
       "2332         -0.265952            -0.379576          -0.566369  ...       0.0   \n",
       "\n",
       "      state_UT  state_VA  state_VT  state_WA  state_WI  state_WV  state_WY  \\\n",
       "0          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "2          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2328       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2329       0.0       0.0       0.0       0.0       0.0       1.0       0.0   \n",
       "2330       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2331       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2332       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      international plan  voice mail plan  \n",
       "0                    0.0              0.0  \n",
       "1                    0.0              0.0  \n",
       "2                    0.0              1.0  \n",
       "3                    1.0              0.0  \n",
       "4                    0.0              0.0  \n",
       "...                  ...              ...  \n",
       "2328                 1.0              0.0  \n",
       "2329                 0.0              1.0  \n",
       "2330                 0.0              0.0  \n",
       "2331                 0.0              0.0  \n",
       "2332                 1.0              0.0  \n",
       "\n",
       "[2333 rows x 68 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(\n",
    "    data = X_train_transformed,\n",
    "    columns=column_names,\n",
    ")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 area code feature\n",
    "rubric={points:4}\n",
    "\n",
    "The original dataset had a feature called `area code`. Let's assume we encoded this feature with one-hot encoding.\n",
    "\n",
    "1. The area codes were numbers to begin with. Why do we want to use one-hot encoding on this feature?\n",
    "2. What were the possible values of `area code`? \n",
    "3. What new feature(s) were created to replace `area code`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([415, 510, 408], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"area code\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution q1 : We would want to use OHE as the numbers are listed as numbers however they are categorical features as area code is a categorical region of certain phone numbers \n",
    "# Solution q2 : Possible Values of area code is 415 510 and 408\n",
    "# Solution q3 : New features that would be created to replace area code would be binary columns of area code_415, area code_510, area code_408"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Dummy classifier\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Create a `DummyClassifier`. Report the following scoring metrics via cross-validation: accuracy, precision, recall, f1-score. Briefly comment on your results, including any warnings the code produces (2 sentences max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.008100\n",
       "score_time     0.003700\n",
       "test_score     0.850408\n",
       "train_score    0.850407\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "dummy = DummyClassifier()\n",
    "pipe = make_pipeline(ct,dummy)\n",
    "pipe.fit(X_train, y_train)\n",
    "pd.DataFrame(cross_validate(pipe, X_train, y_train, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 0.0000, FN = 349.0000,TN = 1984.0000, FP = 0.0000\n",
      "TP = 0.0000, FN = 349.0000\n",
      "Recall: 0.0000\n",
      "TP = 0.0000, FP = 0.0000\n",
      "Precision: nan\n",
      "precision: nan\n",
      "recall: 0.0000\n",
      "f1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_27088\\255900637.py:12: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision = TP / (TP + FP)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "predictions = pipe.predict(X_train)\n",
    "TN, FP, FN, TP = confusion_matrix(y_train, cross_val_predict(pipe, X_train, y_train)).ravel()\n",
    "\n",
    "print(\"TP = %0.4f, FN = %0.4f,TN = %0.4f, FP = %0.4f\" % (TP, FN,TN,FP))\n",
    "\n",
    "print(\"TP = %0.4f, FN = %0.4f\" % (TP, FN))\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Recall: %0.4f\" % (recall))\n",
    "\n",
    "print(\"TP = %0.4f, FP = %0.4f\" % (TP, FP))\n",
    "precision = TP / (TP + FP)\n",
    "print(\"Precision: %0.4f\" % (precision))\n",
    "\n",
    "print(\"precision: %0.4f\" % (precision))\n",
    "print(\"recall: %0.4f\" % (recall))\n",
    "f1_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"f1: %0.4f\" % (f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution The error we are getting is that our True Positive and False Positive were at zero, this is because our dummyclassifier takes the most frequency value which is FALSE or 0 and classifies all our predictions based on False. Based on this we would expect to have 0 positive outcomes as it would all be labeled and False. This results in our equations attempting to divide by zero which gives us an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Logistic regression\n",
    "rubric={points:8} \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Train and score a logistic regression classifier on the dataset. \n",
    "2. Report the same metrics as in the previous part.\n",
    "3. Are you satisfied with the results? Use your `DummyClassifier` results as a reference point. Discuss in a few sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 82.0000, FN = 267.0000\n",
      "Recall: 0.2350\n",
      "TP = 82.0000, FP = 48.0000\n",
      "Precision: 0.6308\n",
      "f1: 0.3424\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "pipe_lr = make_pipeline(ct,lr)\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "predictions = pipe_lr.predict(X_train)\n",
    "TN, FP, FN, TP = confusion_matrix(y_train, predictions).ravel()\n",
    "\n",
    "print(\"TP = %0.4f, FN = %0.4f\" % (TP, FN))\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Recall: %0.4f\" % (recall))\n",
    "\n",
    "print(\"TP = %0.4f, FP = %0.4f\" % (TP, FP))\n",
    "precision = TP / (TP + FP)\n",
    "print(\"Precision: %0.4f\" % (precision))\n",
    "\n",
    "f1_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"f1: %0.4f\" % (f1_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This does preform better than dummyclassifier as we were able to obtain all our data and results. It allows us to get a sense of Recall and Precision before before any hyperparameterization has been preformed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Logistic regression with `class_weight`\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Set the `class_weight` parameter of your logistic regression model to `'balanced'` and report the same metrics as in the previous part. \n",
    "2. Do you prefer this model to the one in the previous part? Discuss your results in a few sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 272.0000, FN = 77.0000\n",
      "Recall: 0.7794\n",
      "TP = 272.0000, FP = 440.0000\n",
      "Precision: 0.3820\n",
      "f1: 0.5127\n"
     ]
    }
   ],
   "source": [
    "pipe_lr_balanced = make_pipeline(ct,LogisticRegression(class_weight=\"balanced\"))\n",
    "pipe_lr_balanced.fit(X_train, y_train)\n",
    "predictions = pipe_lr_balanced.predict(X_train)\n",
    "TN, FP, FN, TP = confusion_matrix(y_train, predictions).ravel()\n",
    "\n",
    "print(\"TP = %0.4f, FN = %0.4f\" % (TP, FN))\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Recall: %0.4f\" % (recall))\n",
    "\n",
    "print(\"TP = %0.4f, FP = %0.4f\" % (TP, FP))\n",
    "precision = TP / (TP + FP)\n",
    "print(\"Precision: %0.4f\" % (precision))\n",
    "\n",
    "f1_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"f1: %0.4f\" % (f1_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution: \n",
    "With balanced our recall and F1 score has increase dramatically with a decrease in our Precision score. For our model if we were most concerns in finding out and capturing all the potential customers that would be leaving us, this result would be ideal or better since we can intervene by contacting potential customers who are thinking about leaving our service before they leave. We are not as concerned with the decrease in precision score as any contact to customers with potential offers to incline them to stay longer would be seen as customer service and we are more focused on capturing those who are on the fence about leaving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Hyperparameter optimization\n",
    "rubric={points:10}\n",
    "\n",
    "Now let's tune the hyperparameters of our `LogisticRegression` using `GridSearchCV` to maximize cross-validation f1 score. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Jointly optimize `C` (choose some reasonable values) and `class_weight` (`None` vs. `'balanced'`) with `GridSearchCV` and `scoring=\"f1\"`. \n",
    "2. What values of `C` and `class_weight` are chosen and what is the best cross-validation f1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'columntransformer', 'logisticregression', 'columntransformer__n_jobs', 'columntransformer__remainder', 'columntransformer__sparse_threshold', 'columntransformer__transformer_weights', 'columntransformer__transformers', 'columntransformer__verbose', 'columntransformer__verbose_feature_names_out', 'columntransformer__pipeline', 'columntransformer__onehotencoder-1', 'columntransformer__onehotencoder-2', 'columntransformer__drop', 'columntransformer__pipeline__memory', 'columntransformer__pipeline__steps', 'columntransformer__pipeline__verbose', 'columntransformer__pipeline__standardscaler', 'columntransformer__pipeline__standardscaler__copy', 'columntransformer__pipeline__standardscaler__with_mean', 'columntransformer__pipeline__standardscaler__with_std', 'columntransformer__onehotencoder-1__categories', 'columntransformer__onehotencoder-1__drop', 'columntransformer__onehotencoder-1__dtype', 'columntransformer__onehotencoder-1__handle_unknown', 'columntransformer__onehotencoder-1__sparse', 'columntransformer__onehotencoder-2__categories', 'columntransformer__onehotencoder-2__drop', 'columntransformer__onehotencoder-2__dtype', 'columntransformer__onehotencoder-2__handle_unknown', 'columntransformer__onehotencoder-2__sparse', 'logisticregression__C', 'logisticregression__class_weight', 'logisticregression__dual', 'logisticregression__fit_intercept', 'logisticregression__intercept_scaling', 'logisticregression__l1_ratio', 'logisticregression__max_iter', 'logisticregression__multi_class', 'logisticregression__n_jobs', 'logisticregression__penalty', 'logisticregression__random_state', 'logisticregression__solver', 'logisticregression__tol', 'logisticregression__verbose', 'logisticregression__warm_start'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"logisticregression__class_weight\": [None,\"balanced\"],\n",
    "    \"logisticregression__C\": [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    pipe_lr, param_grid, cv=5, n_jobs=-1, return_train_score=True,scoring = \"f1\"\n",
    ")\n",
    "grid_search.estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-570cb093-55bd-4606-9d0e-85b810797373 {color: black;background-color: white;}#sk-570cb093-55bd-4606-9d0e-85b810797373 pre{padding: 0;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-toggleable {background-color: white;}#sk-570cb093-55bd-4606-9d0e-85b810797373 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-570cb093-55bd-4606-9d0e-85b810797373 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-570cb093-55bd-4606-9d0e-85b810797373 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-570cb093-55bd-4606-9d0e-85b810797373 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-570cb093-55bd-4606-9d0e-85b810797373 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-570cb093-55bd-4606-9d0e-85b810797373 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-estimator:hover {background-color: #d4ebff;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-item {z-index: 1;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-parallel-item:only-child::after {width: 0;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-570cb093-55bd-4606-9d0e-85b810797373 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-570cb093-55bd-4606-9d0e-85b810797373\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;pipeline&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         [&#x27;account &#x27;\n",
       "                                                                          &#x27;length&#x27;,\n",
       "                                                                          &#x27;number &#x27;\n",
       "                                                                          &#x27;vmail &#x27;\n",
       "                                                                          &#x27;messages&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;charge&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;charge&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;night &#x27;\n",
       "                                                                          &#x27;m...\n",
       "                                                                         OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                                       dtype=&lt;class &#x27;int&#x27;&gt;),\n",
       "                                                                         [&#x27;international &#x27;\n",
       "                                                                          &#x27;plan&#x27;,\n",
       "                                                                          &#x27;voice &#x27;\n",
       "                                                                          &#x27;mail &#x27;\n",
       "                                                                          &#x27;plan&#x27;]),\n",
       "                                                                        (&#x27;drop&#x27;,\n",
       "                                                                         &#x27;drop&#x27;,\n",
       "                                                                         [&#x27;phone &#x27;\n",
       "                                                                          &#x27;number&#x27;,\n",
       "                                                                          &#x27;area &#x27;\n",
       "                                                                          &#x27;code&#x27;])])),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1.0, 10,\n",
       "                                                   100],\n",
       "                         &#x27;logisticregression__class_weight&#x27;: [None,\n",
       "                                                              &#x27;balanced&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f52a939f-7cda-47cf-a394-596788047506\" type=\"checkbox\" ><label for=\"f52a939f-7cda-47cf-a394-596788047506\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;pipeline&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         [&#x27;account &#x27;\n",
       "                                                                          &#x27;length&#x27;,\n",
       "                                                                          &#x27;number &#x27;\n",
       "                                                                          &#x27;vmail &#x27;\n",
       "                                                                          &#x27;messages&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;charge&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;charge&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;night &#x27;\n",
       "                                                                          &#x27;m...\n",
       "                                                                         OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                                       dtype=&lt;class &#x27;int&#x27;&gt;),\n",
       "                                                                         [&#x27;international &#x27;\n",
       "                                                                          &#x27;plan&#x27;,\n",
       "                                                                          &#x27;voice &#x27;\n",
       "                                                                          &#x27;mail &#x27;\n",
       "                                                                          &#x27;plan&#x27;]),\n",
       "                                                                        (&#x27;drop&#x27;,\n",
       "                                                                         &#x27;drop&#x27;,\n",
       "                                                                         [&#x27;phone &#x27;\n",
       "                                                                          &#x27;number&#x27;,\n",
       "                                                                          &#x27;area &#x27;\n",
       "                                                                          &#x27;code&#x27;])])),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1.0, 10,\n",
       "                                                   100],\n",
       "                         &#x27;logisticregression__class_weight&#x27;: [None,\n",
       "                                                              &#x27;balanced&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"17fb4da0-5b8f-4b93-b911-69ea522983e3\" type=\"checkbox\" ><label for=\"17fb4da0-5b8f-4b93-b911-69ea522983e3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;account length&#x27;, &#x27;number vmail messages&#x27;,\n",
       "                                  &#x27;total day minutes&#x27;, &#x27;total day calls&#x27;,\n",
       "                                  &#x27;total day charge&#x27;, &#x27;total eve minutes&#x27;,\n",
       "                                  &#x27;total eve calls&#x27;, &#x27;total eve charge&#x27;,\n",
       "                                  &#x27;total night minutes&#x27;, &#x27;total night calls&#x27;,\n",
       "                                  &#x27;total night charge&#x27;, &#x27;total intl minutes&#x27;,\n",
       "                                  &#x27;total intl calls&#x27;, &#x27;total intl charge&#x27;,\n",
       "                                  &#x27;customer service calls&#x27;]),\n",
       "                                (&#x27;onehotencoder-1&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse=False),\n",
       "                                 [&#x27;state&#x27;]),\n",
       "                                (&#x27;onehotencoder-2&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                               dtype=&lt;class &#x27;int&#x27;&gt;),\n",
       "                                 [&#x27;international plan&#x27;, &#x27;voice mail plan&#x27;]),\n",
       "                                (&#x27;drop&#x27;, &#x27;drop&#x27;,\n",
       "                                 [&#x27;phone number&#x27;, &#x27;area code&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0a441f9d-8b3b-4d0e-a313-97ac7159c3ad\" type=\"checkbox\" ><label for=\"0a441f9d-8b3b-4d0e-a313-97ac7159c3ad\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;account length&#x27;, &#x27;number vmail messages&#x27;, &#x27;total day minutes&#x27;, &#x27;total day calls&#x27;, &#x27;total day charge&#x27;, &#x27;total eve minutes&#x27;, &#x27;total eve calls&#x27;, &#x27;total eve charge&#x27;, &#x27;total night minutes&#x27;, &#x27;total night calls&#x27;, &#x27;total night charge&#x27;, &#x27;total intl minutes&#x27;, &#x27;total intl calls&#x27;, &#x27;total intl charge&#x27;, &#x27;customer service calls&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3a0527ff-9502-43e9-8fa4-ade888e5098f\" type=\"checkbox\" ><label for=\"3a0527ff-9502-43e9-8fa4-ade888e5098f\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"54b9a3a4-32c0-44a8-a76d-1d51b5da9710\" type=\"checkbox\" ><label for=\"54b9a3a4-32c0-44a8-a76d-1d51b5da9710\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehotencoder-1</label><div class=\"sk-toggleable__content\"><pre>[&#x27;state&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"80bb3869-f6cf-470c-ac39-dac145ed4997\" type=\"checkbox\" ><label for=\"80bb3869-f6cf-470c-ac39-dac145ed4997\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"97b43948-43bb-4ea7-b642-3a76b20a72ea\" type=\"checkbox\" ><label for=\"97b43948-43bb-4ea7-b642-3a76b20a72ea\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehotencoder-2</label><div class=\"sk-toggleable__content\"><pre>[&#x27;international plan&#x27;, &#x27;voice mail plan&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"415c8731-fa1e-4573-b4fc-0bab578800f7\" type=\"checkbox\" ><label for=\"415c8731-fa1e-4573-b4fc-0bab578800f7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, dtype=&lt;class &#x27;int&#x27;&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8a98c7df-3dea-4fbf-826a-e9c2c18cca39\" type=\"checkbox\" ><label for=\"8a98c7df-3dea-4fbf-826a-e9c2c18cca39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>[&#x27;phone number&#x27;, &#x27;area code&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"dc827278-1b51-49a3-8e30-1fcb703bb419\" type=\"checkbox\" ><label for=\"dc827278-1b51-49a3-8e30-1fcb703bb419\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>drop</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"917905eb-3e72-43e5-8514-0a186b7570a7\" type=\"checkbox\" ><label for=\"917905eb-3e72-43e5-8514-0a186b7570a7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('pipeline',\n",
       "                                                                         Pipeline(steps=[('standardscaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['account '\n",
       "                                                                          'length',\n",
       "                                                                          'number '\n",
       "                                                                          'vmail '\n",
       "                                                                          'messages',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'minutes',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'calls',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'charge',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'minutes',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'calls',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'charge',\n",
       "                                                                          'total '\n",
       "                                                                          'night '\n",
       "                                                                          'm...\n",
       "                                                                         OneHotEncoder(drop='if_binary',\n",
       "                                                                                       dtype=<class 'int'>),\n",
       "                                                                         ['international '\n",
       "                                                                          'plan',\n",
       "                                                                          'voice '\n",
       "                                                                          'mail '\n",
       "                                                                          'plan']),\n",
       "                                                                        ('drop',\n",
       "                                                                         'drop',\n",
       "                                                                         ['phone '\n",
       "                                                                          'number',\n",
       "                                                                          'area '\n",
       "                                                                          'code'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logisticregression__C': [0.001, 0.01, 0.1, 1.0, 10,\n",
       "                                                   100],\n",
       "                         'logisticregression__class_weight': [None,\n",
       "                                                              'balanced']},\n",
       "             return_train_score=True, scoring='f1')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train) # all the work is done here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced'}\n",
      "0.480993733800413\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution: Our Best C is 0.1 and our best class_weight is balanced with a F1 score of 0.48099"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Test results\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks**\n",
    "1. Evaluate the best model on the test set. In particular show each of the following on the test set:  \n",
    "    - Confusion matrix. \n",
    "    - Classification report. \n",
    "    - Precision-recall curve with average precision score.     \n",
    "    - ROC curve with AUC. \n",
    "3. Comment on the results.    \n",
    "\n",
    "> Note that we are not doing it here but in real life, you would also plot confusion matrix, precision-recall curve, and ROC curve on validation data to examine errors and to choose a threshold which works for your operating point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 100.0000, FN = 34.0000\n",
      "Recall: 0.7463\n",
      "TP = 100.0000, FP = 192.0000\n",
      "Precision: 0.3425\n",
      "f1: 0.4695\n"
     ]
    }
   ],
   "source": [
    "pipe_best = make_pipeline(ct, LogisticRegression(C=0.1,class_weight = \"balanced\"))\n",
    "pipe_best.fit(X_train, y_train)\n",
    "predictions = pipe_lr_balanced.predict(X_test)\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "print(\"TP = %0.4f, FN = %0.4f\" % (TP, FN))\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Recall: %0.4f\" % (recall))\n",
    "\n",
    "print(\"TP = %0.4f, FP = %0.4f\" % (TP, FP))\n",
    "precision = TP / (TP + FP)\n",
    "print(\"Precision: %0.4f\" % (precision))\n",
    "\n",
    "f1_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"f1: %0.4f\" % (f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "disp = plot_confusion_matrix(\n",
    "    pipe_best,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    display_labels=[\"False (Not Churn)\", \"True (Churn)\"],\n",
    "    values_format=\"d\",\n",
    "    cmap=plt.cm.Blues,\n",
    "    colorbar=False,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for Churn data set\n",
      "[[670 196]\n",
      " [ 33 101]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix for Churn data set\")\n",
    "print(disp.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Churn Data set\n",
      "[False  True]\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "False (Not Churn)       0.89      0.96      0.93       866\n",
      "     True (Churn)       0.51      0.26      0.35       134\n",
      "\n",
      "         accuracy                           0.87      1000\n",
      "        macro avg       0.70      0.61      0.64      1000\n",
      "     weighted avg       0.84      0.87      0.85      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report for Churn Data set\")\n",
    "print(pipe_lr.classes_)\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, pipe_lr.predict(X_test), target_names=[\"False (Not Churn)\", \"True (Churn)\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_test, pipe_best.predict_proba(X_test)[:, 1]\n",
    ")\n",
    "plt.plot(precision, recall, label=\"logistic classification: PR curve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.plot(\n",
    "    precision_score(y_test, pipe_lr.predict(X_test)),\n",
    "    recall_score(y_test, pipe_lr.predict(X_test)),\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision of logistic regression: 0.459\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "ap_lr = average_precision_score(y_test, pipe_best.predict_proba(X_test)[:, 1])\n",
    "print(\"Average precision of logistic regression: {:.3f}\".format(ap_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pipe_best.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "\n",
    "default_threshold = np.argmin(np.abs(thresholds - 0.5))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[default_threshold],\n",
    "    tpr[default_threshold],\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area under the curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for logistic regression: 0.823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_lr = roc_auc_score(y_test, pipe_best.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC for logistic regression: {:.3f}\".format(roc_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "We can see from our optimization we have experienced some of the fundamental trade off of having a higher recall score. We trade off precision in order to capture a higher recall score. From our ROC curve we have nearly optimize our recall score as it is in the top left section where recall is the highest while minimizing false positive rate. This has resulted in our average precision rate to be 0.429 but our AUC for our LR to be 0.823. our AUC tells us that 82% of the time a random picked positive point will have a higher score than a randomly picked negative / false point. For classifications with imbalanced classes our AUC has a more meaningful result than looking at just accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Regression metrics <a name=\"3\"></a>\n",
    "<hr> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) from `sklearn datasets`. The code below loads the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing_df = fetch_california_housing(as_frame=True).frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Data spitting and exploration \n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train (80%) and test (20%) splits. \n",
    "2. Explore the train split. Do you need to apply any transformations on the data? If yes, create a preprocessor with the appropriate transformations. \n",
    "3. Separate `X` and `y` in train and test splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16512 entries, 9950 to 19966\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MedInc       16512 non-null  float64\n",
      " 1   HouseAge     16512 non-null  float64\n",
      " 2   AveRooms     16512 non-null  float64\n",
      " 3   AveBedrms    16512 non-null  float64\n",
      " 4   Population   16512 non-null  float64\n",
      " 5   AveOccup     16512 non-null  float64\n",
      " 6   Latitude     16512 non-null  float64\n",
      " 7   Longitude    16512 non-null  float64\n",
      " 8   MedHouseVal  16512 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.3 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9950</th>\n",
       "      <td>4.5694</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.219512</td>\n",
       "      <td>1.030488</td>\n",
       "      <td>504.0</td>\n",
       "      <td>3.073171</td>\n",
       "      <td>38.38</td>\n",
       "      <td>-122.33</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>5.6392</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.951644</td>\n",
       "      <td>1.034816</td>\n",
       "      <td>3010.0</td>\n",
       "      <td>2.911025</td>\n",
       "      <td>34.26</td>\n",
       "      <td>-118.60</td>\n",
       "      <td>2.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>1.7292</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.628032</td>\n",
       "      <td>1.032345</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>3.913747</td>\n",
       "      <td>34.07</td>\n",
       "      <td>-118.21</td>\n",
       "      <td>1.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6984</th>\n",
       "      <td>4.6226</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.126238</td>\n",
       "      <td>0.985149</td>\n",
       "      <td>988.0</td>\n",
       "      <td>2.445545</td>\n",
       "      <td>33.96</td>\n",
       "      <td>-118.02</td>\n",
       "      <td>2.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>2.4375</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.024390</td>\n",
       "      <td>0.942073</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>4.283537</td>\n",
       "      <td>34.08</td>\n",
       "      <td>-118.20</td>\n",
       "      <td>1.140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "9950  4.5694      28.0  6.219512   1.030488       504.0  3.073171     38.38   \n",
       "3547  5.6392      18.0  5.951644   1.034816      3010.0  2.911025     34.26   \n",
       "4448  1.7292      47.0  3.628032   1.032345      1452.0  3.913747     34.07   \n",
       "6984  4.6226      36.0  5.126238   0.985149       988.0  2.445545     33.96   \n",
       "4432  2.4375      49.0  4.024390   0.942073      1405.0  4.283537     34.08   \n",
       "\n",
       "      Longitude  MedHouseVal  \n",
       "9950    -122.33        2.875  \n",
       "3547    -118.60        2.715  \n",
       "4448    -118.21        1.917  \n",
       "6984    -118.02        2.197  \n",
       "4432    -118.20        1.140  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(housing_df, test_size=0.20, random_state=123)\n",
    "print(train_df.info())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our observation it appears that there are no missing data, and all our values are encoded as floats. The main transformation we would need to do is to scale our data. This would end up being a regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 {color: black;background-color: white;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 pre{padding: 0;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-toggleable {background-color: white;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-estimator:hover {background-color: #d4ebff;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-item {z-index: 1;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-parallel-item:only-child::after {width: 0;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-5e74a41f-e4d5-46ae-a5f0-8e4abf302726\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;MedInc&#x27;, &#x27;HouseAge&#x27;, &#x27;AveRooms&#x27;, &#x27;AveBedrms&#x27;,\n",
       "                                  &#x27;Population&#x27;, &#x27;AveOccup&#x27;, &#x27;Latitude&#x27;,\n",
       "                                  &#x27;Longitude&#x27;])])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1641ebcb-0cdd-405a-8870-3cf219fe2b4c\" type=\"checkbox\" ><label for=\"1641ebcb-0cdd-405a-8870-3cf219fe2b4c\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;MedInc&#x27;, &#x27;HouseAge&#x27;, &#x27;AveRooms&#x27;, &#x27;AveBedrms&#x27;,\n",
       "                                  &#x27;Population&#x27;, &#x27;AveOccup&#x27;, &#x27;Latitude&#x27;,\n",
       "                                  &#x27;Longitude&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5b2361bb-d051-4ebd-b926-03276f7142fe\" type=\"checkbox\" ><label for=\"5b2361bb-d051-4ebd-b926-03276f7142fe\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;MedInc&#x27;, &#x27;HouseAge&#x27;, &#x27;AveRooms&#x27;, &#x27;AveBedrms&#x27;, &#x27;Population&#x27;, &#x27;AveOccup&#x27;, &#x27;Latitude&#x27;, &#x27;Longitude&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"880d13bd-17b4-4e18-b63b-24559315a736\" type=\"checkbox\" ><label for=\"880d13bd-17b4-4e18-b63b-24559315a736\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"be1ff3b5-9698-4689-b31b-fb32b8d2a649\" type=\"checkbox\" ><label for=\"be1ff3b5-9698-4689-b31b-fb32b8d2a649\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('pipeline',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler())]),\n",
       "                                 ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms',\n",
       "                                  'Population', 'AveOccup', 'Latitude',\n",
       "                                  'Longitude'])])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "numerical_feats = [\"MedInc\",\"HouseAge\",\"AveRooms\",\"AveBedrms\",\"Population\",\"AveOccup\",\"Latitude\",\"Longitude\"]\n",
    "ct2 = make_column_transformer(\n",
    "    (\n",
    "        make_pipeline(SimpleImputer(strategy=\"median\"),StandardScaler()),\n",
    "        numerical_feats,\n",
    "    ), # scaling on numeric features\n",
    ")\n",
    "ct2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"MedHouseVal\"])\n",
    "X_test = test_df.drop(columns=[\"MedHouseVal\"])\n",
    "\n",
    "y_train = train_df[\"MedHouseVal\"]\n",
    "y_test = test_df[\"MedHouseVal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Baseline: DummyRegressor \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out cross-validation using `DummyRegressor` with default scoring. \n",
    "2. What metric is used for scoring by default? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>-0.001050</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000663</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>-0.001729</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000802</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.002000    0.000500   -0.001675          0.0\n",
       "1  0.001500    0.000500   -0.001050          0.0\n",
       "2  0.001499    0.000000   -0.000509          0.0\n",
       "3  0.000999    0.000500   -0.000349          0.0\n",
       "4  0.001502    0.000000   -0.000663          0.0\n",
       "5  0.000998    0.000499   -0.001729          0.0\n",
       "6  0.001500    0.000000   -0.000094          0.0\n",
       "7  0.001000    0.000500   -0.000008          0.0\n",
       "8  0.001000    0.000500   -0.000222          0.0\n",
       "9  0.001500    0.000000   -0.000802          0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyRegressor()\n",
    "pd.DataFrame(cross_validate(dummy, X_train, y_train, cv=10, return_train_score=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BY default our scoring is based off of R^2 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Different regressors\n",
    "rubric={points:8}\n",
    "\n",
    "In this exercise, we are going to use [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) model which we haven't looked into yet. At this point you should feel comfortable using models with our usual ML workflow even if you don't know the details. We'll talk about `RandomForestRegressor` later in the course.  \n",
    "\n",
    "The code below defines a custom scorer called `mape_scorer` and creates dictionaries for different regressors (`models`) and different scoring metrics (`score_types_reg`). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Using the `models` and the evaluation metrics `score_types_reg` in the code below, carry out cross-validation with each model, by passing the evaluation metrics to `scoring` argument of `cross_validate`. Use a pipeline with the model as an estimator if you are applying any transformations. \n",
    "2. Show results as a dataframe. \n",
    "3. Interpret the results. How do the models compare to the baseline? Which model seems to be performing well with different metrics? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(true, pred):\n",
    "    return 100.0 * np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "# make a scorer function that we can pass into cross-validation\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "score_types_reg = {\n",
    "    \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "    \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"mape_scorer\": mape_scorer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "lr_ridge = make_pipeline(ct2,Ridge())\n",
    "lr_forest = make_pipeline(ct2,RandomForestRegressor())\n",
    "Ridges = cross_validate(\n",
    "            lr_ridge,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            return_train_score=True,\n",
    "            scoring = score_types_reg)\n",
    "Forests = cross_validate(\n",
    "            lr_forest,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            return_train_score=True,\n",
    "            scoring = score_types_reg)\n",
    "\n",
    "result = {\n",
    "    \"Ridge\": pd.DataFrame(Ridges).mean().tolist(),\n",
    "    \"Random Forest\": pd.DataFrame(Forests).mean().tolist(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.016800</td>\n",
       "      <td>5.289201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.069800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <td>-0.683433</td>\n",
       "      <td>-0.262817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <td>-0.524369</td>\n",
       "      <td>-0.036510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <td>-0.810381</td>\n",
       "      <td>-0.512573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <td>-0.724132</td>\n",
       "      <td>-0.191060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <td>-0.535444</td>\n",
       "      <td>-0.333942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <td>-0.531388</td>\n",
       "      <td>-0.124619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>0.481744</td>\n",
       "      <td>0.802459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2</th>\n",
       "      <td>0.606300</td>\n",
       "      <td>0.972585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mape_scorer</th>\n",
       "      <td>-31.979551</td>\n",
       "      <td>-18.863464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mape_scorer</th>\n",
       "      <td>-31.762979</td>\n",
       "      <td>-7.027324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Ridge  Random Forest\n",
       "fit_time                            0.016800       5.289201\n",
       "score_time                          0.003700       0.069800\n",
       "test_neg_mean_squared_error        -0.683433      -0.262817\n",
       "train_neg_mean_squared_error       -0.524369      -0.036510\n",
       "test_neg_root_mean_squared_error   -0.810381      -0.512573\n",
       "train_neg_root_mean_squared_error  -0.724132      -0.191060\n",
       "test_neg_mean_absolute_error       -0.535444      -0.333942\n",
       "train_neg_mean_absolute_error      -0.531388      -0.124619\n",
       "test_r2                             0.481744       0.802459\n",
       "train_r2                            0.606300       0.972585\n",
       "test_mape_scorer                  -31.979551     -18.863464\n",
       "train_mape_scorer                 -31.762979      -7.027324"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result, index=Ridges.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "\n",
    "Looking at our results it appears for our CV, Random Forest appears to be a better fit with Negative Mean Squared error, Neg RMSE, neg mean absolute error, r^2 and Mape all scoring better than Ridge. With R^2 being closer to 1 and all other scorings being closer to zero. Compared to baseline our R^2 score for baseline was close to 0 (not ideal as r^2 we want a score closest to 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 3.4 Hyperparameter optimization \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out hyperparameter optimization using `RandomizedSearchCV` and `Ridge` with the following `param_dist`. The `alpha` hyperparameter of `Ridge` controls the fundamental tradeoff. Choose the metric of your choice for hyperparameter optimization. \n",
    "2. Are you getting better scores compared to the default values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "param_dist = {\"ridge__alpha\": loguniform(1e-3, 1e3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Test results\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try the best model on the test set.\n",
    "2. Briefly comment on the results. (1 to 2 sentences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.258396197588773"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forest_Best = lr_forest.fit(X_train,y_train)\n",
    "\n",
    "mape(y_test, Forest_Best.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution \n",
    "\n",
    "Our best model with our Forest Regressor was able to predict from our test data with an accuracy of 18%. This means on average we have around a 18% error in our predicted scores. This result matches our train cross validation mean score from above which means our model is doing its job in not over or under fitting the data. 18% is still a better result than using our Ridge Regressor model (prior to any tuning of hyperparams.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Model interpretation  \n",
    "rubric={points:4}\n",
    "\n",
    "Ridge is a linear model and it learns coefficients associated with each feature during `fit()`. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Visualize coefficients learned by the `Ridge` model above as a pandas dataframe with two columns: features and coefficients. If you attempted 3.4, use the `Ridge` model with best hyperparameters. Otherwise use the `Ridge` model with default hyperparameters. \n",
    "2. Increasing which feature values would result in higher housing price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MedInc</td>\n",
       "      <td>0.835964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AveBedrms</td>\n",
       "      <td>0.318049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HouseAge</td>\n",
       "      <td>0.115302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Population</td>\n",
       "      <td>-0.007375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AveOccup</td>\n",
       "      <td>-0.041683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AveRooms</td>\n",
       "      <td>-0.281707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>-0.854789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>-0.889398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features  coefficients\n",
       "0      MedInc      0.835964\n",
       "3   AveBedrms      0.318049\n",
       "1    HouseAge      0.115302\n",
       "4  Population     -0.007375\n",
       "5    AveOccup     -0.041683\n",
       "2    AveRooms     -0.281707\n",
       "7   Longitude     -0.854789\n",
       "6    Latitude     -0.889398"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_Best = lr_ridge.fit(X_train,y_train)\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"features\": numerical_feats,\n",
    "        \"coefficients\": Ridge_Best.named_steps[\"ridge\"].coef_,\n",
    "    }\n",
    ")\n",
    "df.sort_values(\"coefficients\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution: Based on our data we would expect that increasing median income in block group or MedInc would result in the largest increase in housing price as it has the highest positive coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "name": "_merged",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "438px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
